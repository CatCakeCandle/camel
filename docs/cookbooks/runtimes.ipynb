{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5_pa5kKPzAE"
   },
   "source": [
    "# Runtimes Cookbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSXa_rQQQzBd"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnmoAw2vQG8I"
   },
   "source": [
    "In this tutorial, we will explore the `Runtimes` in CAMEL, focusing on three specific runtime implementations: \n",
    "\n",
    "1. `LLMGuardRuntime`: This runtime evaluates the risk level of functions using a language model. It ensures that potentially harmful functions are assessed and controlled before execution. The runtime uses a prompt-based approach to determine the risk score of a function based on its description and parameters.\n",
    "\n",
    "2. `RemoteHttpRuntime`: This runtime allows functions to be executed on a remote HTTP server. It is useful for distributing workloads across different servers and ensuring that functions run in a controlled remote environment. The runtime supports custom entry points and arguments, and provides mechanisms to check server status and wait for readiness.\n",
    "\n",
    "3. `DockerRuntime`: This runtime provides a containerized environment for executing functions using Docker. It ensures that functions run in isolated and reproducible environments, making it ideal for complex workflows and dependency management. The runtime supports mounting directories, copying files to containers, and adding tasks to execute commands inside containers.\n",
    "\n",
    "Each of these runtimes provides a unique environment for executing functions, ensuring safety, remote execution, and containerized execution, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4MP9uUNQ2kr"
   },
   "source": [
    "## Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYzY4OM6F3ay"
   },
   "source": [
    "The `BaseRuntime` class is the base class for runtime environments used in the CAMEL system. It is designed to provide a consistent structure for executing functions in different environments and allows for easy extension to support various runtime implementations. The `BaseRuntime` class ensures that functions are executed in a controlled and predictable manner, providing mechanisms for initialization, execution, and cleanup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kETDiaP2Rrdb"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cg96MkbcRtQR"
   },
   "source": [
    "Ensure you have CAMEL AI installed in your Python environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZVmDAK6MPefC"
   },
   "outputs": [],
   "source": [
    "!pip install \"camel-ai==0.2.14\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to try DockerRuntime, please make sure you have Docker installed in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyTTCe3IR_Lr"
   },
   "source": [
    "### Setting Up API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REqzgGL9SEaD"
   },
   "source": [
    "You'll need to set up your API keys for OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNBFEXc-R-0s",
    "outputId": "3efcae2c-a001-4098-a78f-bb8fb611925f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Prompt for the API key securely\n",
    "openai_api_key = getpass('Enter your API key: ')\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class RuntimeLogFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return \"camel.runtimes\" in record.name\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "stream_handler.addFilter(RuntimeLogFilter())\n",
    "\n",
    "\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(stream_handler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9RKJHGBXvfd"
   },
   "source": [
    "## LLMGuardRuntime\n",
    "\n",
    "### Overview\n",
    "\n",
    "`LLMGuardRuntime` is a specialized runtime designed to evaluate and manage the risks associated with executing functions in applications where safety, compliance, or security are critical. It leverages a language model to assess potential risks and provides tools to mitigate or ignore them based on predefined criteria.\n",
    "\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Risk Evaluation**: Utilizes a language model to evaluate the risk associated with executing a function.\n",
    "- **Risk Scoring**: Assigns scores to functions based on predefined risk criteria.\n",
    "- **Risk Mitigation**: Allows for the implementation of mechanisms to ignore or handle certain risks, offering flexibility in application behavior.\n",
    "- **Seamless Integration**: Compatible with tools in camel for easy adoption and integration into existing workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKcOX661Xvfd",
    "outputId": "aacee56c-7f1e-4220-d98d-f08baeaabb0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 22:57:57,429 - camel.agents.chat_agent - WARNING - Overriding the configured tools in `BaseModelBackend` with the tools from `ChatAgent`.\n",
      "2024-12-26 22:57:58,500 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-26 22:57:58,502 - camel.agents.chat_agent - INFO - Model gpt-4o-mini, index 0, processed these messages: [{'role': 'system', 'content': \"You are a function safety evaluator tasked with assessing the \\npotential risk level of a given function based on both its description \\nand parameters. Your goal is to determine if the function may pose any \\nharm to the user's environment, such as deleting files, executing \\narbitrary code, or accessing sensitive information. Pay special attention \\nto the provided parameters â€” even if a function has the potential to be \\ndangerous, its actual parameters may indicate harmless behavior, and the \\nrisk level should be adjusted accordingly. Use the `function_risk` tool to \\nassign a risk score to the function, based on the following criteria:\\n\\n- **Score 1**: No harm. This includes simple operations like mathematical \\n    calculations, content searches, or data retrievals that do not impact \\n    the user's environment or access sensitive resources. This also \\n    includes functions with potentially dangerous capabilities that have \\n    harmless, controlled parameters that ensure safe execution.\\n- **Score 2**: Minimal harm. The function might read user files, retrieve \\n    non-sensitive data, or access other low-risk resources, \\n    posing little risk to the user.\\n- **Score 3**: Risk present. The function might delete files, modify the \\n    file system, execute arbitrary code, or access sensitive data, which \\n    could negatively impact the user's environment. However, if the \\n    actual parameters provided clearly indicate safe and restricted \\n    usage, this risk should be downgraded accordingly.\\n\\nWhen evaluating, always consider both the function's description and its \\nspecific parameters. If the function appears risky due to its design but \\nthe provided parameters indicate a safe and non-impactful operation, \\nadjust the risk score to reflect this. Assign an appropriate risk score \\nand provide a brief explanation of your reasoning based on the function's \\ndescription and the actual parameters given.\\nYOU MUST USE THE `function_risk` TOOL TO ASSESS THE RISK \\nLEVEL OF EACH FUNCTION.\\n\"}, {'role': 'user', 'content': '\\n                    Function is: example_function\\n                    Function description: \\n                    Args: (1, 2)\\n                    Kwargs: {}\\n                    '}]\n",
      "2024-12-26 22:57:58,503 - camel.runtimes.llm_guard_runtime - INFO - Function example_function passed risk assessment.Score: 1, Reason: The function 'example_function' takes two integer arguments and has no keyword arguments. Since it appears to perform a simple operation with these integers, such as a mathematical calculation, it poses no harm to the user's environment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 22:57:58,503 - camel.runtimes.llm_guard_runtime - INFO - Function example_function passed risk assessment.Score: 1, Reason: The function 'example_function' takes two integer arguments and has no keyword arguments. Since it appears to perform a simple operation with these integers, such as a mathematical calculation, it poses no harm to the user's environment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from camel.runtimes.llm_guard_runtime import LLMGuardRuntime\n",
    "from camel.toolkits import FunctionTool\n",
    "\n",
    "\n",
    "def example_function(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "tool = FunctionTool(example_function)\n",
    "runtime = LLMGuardRuntime()\n",
    "runtime.add(tool)\n",
    "result = tool.func(1, 2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### When to Use `LLMGuardRuntime`\n",
    "\n",
    "You should consider using `LLMGuardRuntime` in the following scenarios:\n",
    "\n",
    "1. **Sensitive Operations**: When the execution of functions may involve sensitive or critical data, and an evaluation of risks is essential.\n",
    "   \n",
    "2. **Compliance Requirements**: In environments where regulatory or compliance frameworks demand thorough risk assessments before executing operations.\n",
    "\n",
    "3. **Dynamic Risk Management**: When applications require dynamic evaluation and scoring of functions to determine their safety and alignment with predefined criteria.\n",
    "\n",
    "4. **Controlled Flexibility**: If you need the ability to selectively ignore certain risks while maintaining control over others.\n",
    "\n",
    "5. **AI-Driven Decision Making**: When leveraging AI to predict and mitigate risks associated with runtime operations can add value.\n",
    "\n",
    "\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- **Proactive Risk Mitigation**: By evaluating functions before execution, potential issues can be flagged and addressed preemptively.\n",
    "- **Customizable Criteria**: Users can define their own risk criteria, tailoring the runtime to specific application needs.\n",
    "- **Enhanced Security**: Reduces the likelihood of unintended consequences by monitoring and managing function execution risks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5scuZsGYGS9"
   },
   "source": [
    "## RemoteHttpRuntime\n",
    "\n",
    "### Overview\n",
    "\n",
    "`RemoteHttpRuntime` is a runtime designed to execute functions on a remote HTTP server, enabling distributed and scalable execution of tasks. It supports customization of entry points, arguments, and provides mechanisms to ensure server readiness and reliability during execution.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Remote Execution**: Executes functions on a designated HTTP server for distributed processing.\n",
    "- **Custom Entry Points**: Allows configuration of custom entry points and arguments for tailored operations.\n",
    "- **Seamless Integration**: Compatible with tools in camel for easy adoption and integration into existing workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for runtime to be ready...\n",
      "2024-12-12 23:30:51,108 - camel - INFO - Camel library logging has been configured.\n",
      "2024-12-12 23:30:51,728 - __main__ - INFO - Modules and functions: ['camel.toolkits.MathToolkit']\n",
      "2024-12-12 23:30:51,729 - __main__ - INFO - Importing camel.toolkits and function MathToolkit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Will watch for changes in these directories: ['/home/lxk/camel/docs/cookbooks']\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
      "INFO:     Started reloader process [674247] using WatchFiles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 23:30:52,167 - camel - INFO - Camel library logging has been configured.\n",
      "2024-12-12 23:30:52,819 - __mp_main__ - INFO - Modules and functions: ['camel.toolkits.MathToolkit']\n",
      "2024-12-12 23:30:52,820 - __mp_main__ - INFO - Importing camel.toolkits and function MathToolkit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [674287]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:60696 - \"GET / HTTP/1.1\" 404 Not Found\n",
      "Runtime is ready.\n",
      "INFO:     127.0.0.1:60410 - \"POST /add HTTP/1.1\" 200 OK\n",
      "Add 1 + 2: 3\n",
      "INFO:     127.0.0.1:60420 - \"POST /sub HTTP/1.1\" 200 OK\n",
      "Subtract 5 - 3: 2\n",
      "INFO:     127.0.0.1:60436 - \"POST /multiply HTTP/1.1\" 200 OK\n",
      "Multiply 2 * 3: 6\n",
      "Documents:  http://localhost:8000/docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [674287]\n",
      "INFO:     Stopping reloader process [674247]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<camel.runtimes.remote_http_runtime.RemoteHttpRuntime at 0x7f9fd48f7170>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from camel.runtimes.remote_http_runtime import RemoteHttpRuntime\n",
    "from camel.toolkits.math_toolkit import MathToolkit\n",
    "\n",
    "runtime = (\n",
    "        RemoteHttpRuntime(\"localhost\")\n",
    "        .add(MathToolkit().get_tools(), \"camel.toolkits.MathToolkit\")\n",
    "        .build()\n",
    "    )\n",
    "print(\"Waiting for runtime to be ready...\")\n",
    "runtime.wait()\n",
    "print(\"Runtime is ready.\")\n",
    "add, sub, mul, _, _ = runtime.get_tools()\n",
    "print(f\"Add 1 + 2: {add.func(1, 2)}\")\n",
    "print(f\"Subtract 5 - 3: {sub.func(5, 3)}\")\n",
    "print(f\"Multiply 2 * 3: {mul.func(2, 3)}\")\n",
    "\n",
    "print(\"Documents: \", runtime.docs)\n",
    "# you can open this url in browser to see the API Endpoints\n",
    "# before the runtime is stopped.\n",
    "# time.sleep(60)\n",
    "runtime.stop()\n",
    "# call runtime.stop() if you want to stop the runtime manually\n",
    "# atherwise it will be stopped automatically when the program ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use `RemoteHttpRuntime`\n",
    "\n",
    "Consider using `RemoteHttpRuntime` in the following scenarios:\n",
    "\n",
    "1. **Distributed Computing**: When tasks need to be executed across remote servers for scalability and performance.\n",
    "   \n",
    "2. **Centralized Function Hosting**: If functions are hosted on a central server and accessed remotely by various clients.\n",
    "\n",
    "3. **Customizable API Endpoints**: For applications requiring custom entry points and specific arguments for remote execution.\n",
    "\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- **Scalability**: Enables distributed task execution across remote servers, enhancing scalability.\n",
    "- **Flexibility**: Supports custom configurations to meet specific application needs.\n",
    "- **Reliability**: Provides robust mechanisms to verify runtime readiness before execution.\n",
    "- **Integration-Friendly**: Compatible with toolkits for quick and efficient integration.\n",
    "\n",
    "\n",
    "\n",
    "### Notes on Usage\n",
    "\n",
    "1. **Server Address**: Ensure the correct HTTP server address is provided during initialization.\n",
    "2. **Documentation Access**: The `runtime.docs` property provides API documentation for easy reference.\n",
    "3. **Runtime Stopping**: Always stop the runtime using `runtime.stop()` to free resources when it is no longer needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRojeqp7dP1m"
   },
   "source": [
    "## DockerRuntime\n",
    "\n",
    "### Overview\n",
    "\n",
    "`DockerRuntime` enables the execution of functions within Docker containers, providing a controlled and isolated environment for running tasks. It supports directory mounting, file transfers, and seamless task execution, making it ideal for use cases requiring reproducibility and isolation.\n",
    "\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Docker-Based Execution**: Executes functions within Docker containers, ensuring an isolated runtime environment.\n",
    "- **Directory Mounting**: Allows mounting of local directories into the container for resource sharing.\n",
    "- **File Transfer Support**: Facilitates copying files to and from the container for streamlined workflows.\n",
    "- **Task Execution**: Provides mechanisms to add tasks and execute commands inside the container.\n",
    "- **Seamless Integration**: Compatible with tools in camel for easy adoption and integration into existing workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 23:34:31,918 - camel.runtimes.docker_runtime - INFO - Copying /home/lxk/camel/camel/runtimes/api.py to /home\n",
      "2024-12-12 23:34:31,983 - camel.runtimes.docker_runtime - INFO - Container started on port 8000\n",
      "Waiting for runtime to be ready...\n",
      "Runtime is ready.\n",
      "Executed the code below:\n",
      "```py\n",
      "2 ** 10\n",
      "```\n",
      "> Executed Results:\n",
      "1024\n",
      "\n",
      "2024-12-12 23:34:46,676 - camel.runtimes.docker_runtime - INFO - Removing container.\n"
     ]
    }
   ],
   "source": [
    "from camel.runtimes import DockerRuntime\n",
    "from camel.toolkits.code_execution import CodeExecutionToolkit\n",
    "\n",
    "\n",
    "# tools\n",
    "toolkit = CodeExecutionToolkit(verbose=True)\n",
    "\n",
    "# change to your own docker image\n",
    "runtime = DockerRuntime(\"xukunliu/camel\").add(\n",
    "    toolkit.get_tools(),\n",
    "    \"camel.toolkits.CodeExecutionToolkit\",\n",
    "    redirect_stdout=True,\n",
    "    arguments=dict(verbose=True),\n",
    ")\n",
    "\n",
    "tool = runtime.get_tools()[0]\n",
    "\n",
    "with runtime as r:\n",
    "    print(\"Waiting for runtime to be ready...\")\n",
    "    r.wait()\n",
    "    print(\"Runtime is ready.\")\n",
    "    tool.func(\"2 ** 10\")\n",
    "\n",
    "print(\"DockerRuntime stopped\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### When to Use `DockerRuntime`\n",
    "\n",
    "You should consider using `DockerRuntime` in the following scenarios:\n",
    "\n",
    "1. **Environment Isolation**: When tasks require isolated environments to avoid interference or conflicts with the host system.\n",
    "   \n",
    "2. **Reproducibility**: For workflows that demand reproducible environments across different systems.\n",
    "\n",
    "3. **Resource Sharing**: If tasks involve sharing resources such as files or directories between the host and the container.\n",
    "\n",
    "4. **Code Execution**: When executing scripts or commands using a toolkit like `CodeExecutionToolkit` within a Dockerized environment.\n",
    "\n",
    "5. **Customized Docker Images**: If your application depends on specific Docker images configured with the required dependencies.\n",
    "\n",
    "\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- **Isolation**: Ensures tasks are executed in a clean and controlled environment.\n",
    "- **Flexibility**: Allows integration with toolkits for custom workflows.\n",
    "- **Resource Sharing**: Facilitates efficient sharing of data and files with containers.\n",
    "- **Ease of Use**: Provides a high-level API for managing and interacting with Docker containers.\n",
    "\n",
    "\n",
    "### Notes on Usage\n",
    "\n",
    "1. **Docker Image**: Replace `\"xukunliu/camel\"` with your specific Docker image.\n",
    "2. **Directory Mounting**: Use directory mounting to provide access to local files inside the container if needed.\n",
    "3. **File Management**: Leverage file transfer capabilities to streamline workflows.\n",
    "4. **Stopping Runtime**: The runtime is automatically stopped when the program ends or when exiting the context manager.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `Runtimes` with Agent\n",
    "\n",
    "In this section, we will demonstrate how to use the `Runtime` with an agent in the CAMEL system. \n",
    "\n",
    "The `Runtime` class provides an `add` function that allows you to add `FunctionTool` instances to the runtime and use `get_tools` to retrieve the wrapped functions. These functions behave exactly like the original functions, and you can add them to the agent just like any other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 23:54:28,291 - camel.agents.chat_agent - WARNING - Overriding the configured tools in `BaseModelBackend` with the tools from `ChatAgent`.\n",
      "2024-12-12 23:54:30,513 - camel.runtimes.docker_runtime - INFO - Copying /home/lxk/camel/camel/runtimes/api.py to /home\n",
      "2024-12-12 23:54:30,605 - camel.runtimes.docker_runtime - INFO - Container started on port 8000\n",
      "\u001b[33muser prompt:\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 51 minutes of babysitting. How much did she earn?\n",
      "\n",
      "2024-12-12 23:54:38,240 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 23:54:38,304 - camel.agents.chat_agent - INFO - Model gpt-4o, index 0, processed these messages: [{'role': 'system', 'content': 'You are a personal math tutor and programmer. When asked a math question, write and run Python code to answer the question.'}, {'role': 'user', 'content': 'Weng earns $12 an hour for babysitting. Yesterday, she just did 51 minutes of babysitting. How much did she earn?'}]\n",
      "\n",
      "2024-12-12 23:54:38,944 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 23:54:38,947 - camel.agents.chat_agent - INFO - Model gpt-4o, index 0, processed these messages: [{'role': 'system', 'content': 'You are a personal math tutor and programmer. When asked a math question, write and run Python code to answer the question.'}, {'role': 'user', 'content': 'Weng earns $12 an hour for babysitting. Yesterday, she just did 51 minutes of babysitting. How much did she earn?'}, {'role': 'assistant', 'content': '', 'function_call': {'name': 'execute_code', 'arguments': '{\\'code\\': \"# Weng\\'s hourly rate\\\\nhourly_rate = 12\\\\n\\\\n# Time spent babysitting in minutes\\\\ntime_in_minutes = 51\\\\n\\\\n# Convert minutes to hours\\\\nhours_worked = time_in_minutes / 60\\\\n\\\\n# Calculate earnings\\\\nearnings = hourly_rate * hours_worked\\\\nearnings\"}'}}, {'role': 'function', 'name': 'execute_code', 'content': '{\\'result\\': {\"Executed the code below:\\\\n```py\\\\n# Weng\\'s hourly rate\\\\nhourly_rate = 12\\\\n\\\\n# Time spent babysitting in minutes\\\\ntime_in_minutes = 51\\\\n\\\\n# Convert minutes to hours\\\\nhours_worked = time_in_minutes / 60\\\\n\\\\n# Calculate earnings\\\\nearnings = hourly_rate * hours_worked\\\\nearnings\\\\n```\\\\n> Executed Results:\\\\n10.2\"}}'}]\n",
      "2024-12-12 23:54:38,950 - camel.camel.utils.commons - INFO - \n",
      "\u001b[32mAgent response:\n",
      "Weng earned $10.20 for 51 minutes of babysitting.\n",
      "2024-12-12 23:54:40,441 - camel.camel.utils.commons - INFO - \n",
      "2024-12-12 23:54:51,053 - camel.runtimes.docker_runtime - INFO - Removing container.\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore\n",
    "from camel.agents import ChatAgent\n",
    "from camel.configs import ChatGPTConfig\n",
    "from camel.messages import BaseMessage\n",
    "from camel.models import ModelFactory\n",
    "from camel.runtimes import DockerRuntime\n",
    "from camel.toolkits.code_execution import CodeExecutionToolkit\n",
    "from camel.types import ModelPlatformType, ModelType\n",
    "from camel.utils import print_text_animated\n",
    "\n",
    "# Initialize the CodeExecutionToolkit\n",
    "toolkit = CodeExecutionToolkit(verbose=True)\n",
    "\n",
    "# Initialize the DockerRuntime with a specified Docker image\n",
    "runtime = DockerRuntime(\"xukunliu/camel\").add(\n",
    "    toolkit.get_tools(),\n",
    "    \"camel.toolkits.CodeExecutionToolkit\",\n",
    "    redirect_stdout=True,\n",
    ")\n",
    "\n",
    "# Retrieve the tools from the runtime\n",
    "tools = runtime.get_tools()\n",
    "\n",
    "# Configure the language model\n",
    "assistant_model_config = ChatGPTConfig(\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Create the model using the ModelFactory\n",
    "model = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.DEFAULT,\n",
    "    model_type=ModelType.GPT_4O,\n",
    "    model_config_dict=assistant_model_config.as_dict(),\n",
    ")\n",
    "\n",
    "# Create the system message for the agent\n",
    "assistant_sys_msg = BaseMessage.make_assistant_message(\n",
    "    role_name=\"Teacher\",\n",
    "    content=(\n",
    "        \"You are a personal math tutor and programmer. \"\n",
    "        \"When asked a math question, \"\n",
    "        \"write and run Python code to answer the question.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Initialize the ChatAgent with the system message, model, and tools\n",
    "agent = ChatAgent(\n",
    "    assistant_sys_msg,\n",
    "    model,\n",
    "    tools=tools,\n",
    ")\n",
    "agent.reset()\n",
    "\n",
    "# Use the runtime to execute the task\n",
    "with runtime as r:\n",
    "    r.wait()\n",
    "    prompt = (\n",
    "        \"Weng earns $12 an hour for babysitting. \"\n",
    "        \"Yesterday, she just did 51 minutes of babysitting. How much did she earn?\"\n",
    "    )\n",
    "    user_msg = BaseMessage.make_user_message(role_name=\"User\", content=prompt)\n",
    "    print(Fore.YELLOW + f\"user prompt:\\n{prompt}\\n\")\n",
    "\n",
    "    # Get the agent's response to the user message\n",
    "    response = agent.step(user_msg)\n",
    "    for msg in response.msgs:\n",
    "        print_text_animated(Fore.GREEN + f\"Agent response:\\n{msg.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYNA7G06FJRq"
   },
   "source": [
    "In this session, we introduced the BaseRuntime class and its specific runtime implementations. These components play essential roles in the CAMEL system, facilitating the execution of functions in various environments with safety, remote execution, and containerized execution."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
