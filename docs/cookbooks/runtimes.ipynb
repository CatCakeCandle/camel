{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5_pa5kKPzAE"
   },
   "source": [
    "# Runtimes Cookbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSXa_rQQQzBd"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnmoAw2vQG8I"
   },
   "source": [
    "In this tutorial, we will explore the `Runtimes` in CAMEL, focusing on three specific runtime implementations: \n",
    "\n",
    "1. `LLMGuardRuntime`: This runtime evaluates the risk level of functions using a language model. It ensures that potentially harmful functions are assessed and controlled before execution. The runtime uses a prompt-based approach to determine the risk score of a function based on its description and parameters.\n",
    "\n",
    "2. `RemoteHttpRuntime`: This runtime allows functions to be executed on a remote HTTP server. It is useful for distributing workloads across different servers and ensuring that functions run in a controlled remote environment. The runtime supports custom entry points and arguments, and provides mechanisms to check server status and wait for readiness.\n",
    "\n",
    "3. `DockerRuntime`: This runtime provides a containerized environment for executing functions using Docker. It ensures that functions run in isolated and reproducible environments, making it ideal for complex workflows and dependency management. The runtime supports mounting directories, copying files to containers, and adding tasks to execute commands inside containers.\n",
    "\n",
    "Each of these runtimes provides a unique environment for executing functions, ensuring safety, remote execution, and containerized execution, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4MP9uUNQ2kr"
   },
   "source": [
    "## Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYzY4OM6F3ay"
   },
   "source": [
    "The `BaseRuntime` class is the base class for runtime environments used in the CAMEL system. It is designed to provide a consistent structure for executing functions in different environments and allows for easy extension to support various runtime implementations. The `BaseRuntime` class ensures that functions are executed in a controlled and predictable manner, providing mechanisms for initialization, execution, and cleanup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kETDiaP2Rrdb"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cg96MkbcRtQR"
   },
   "source": [
    "Ensure you have CAMEL AI installed in your Python environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZVmDAK6MPefC"
   },
   "outputs": [],
   "source": [
    "!pip install \"camel-ai\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to try DockerRuntime, please make sure you have Docker installed in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyTTCe3IR_Lr"
   },
   "source": [
    "### Setting Up API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REqzgGL9SEaD"
   },
   "source": [
    "You'll need to set up your API keys for OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNBFEXc-R-0s",
    "outputId": "3efcae2c-a001-4098-a78f-bb8fb611925f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Prompt for the API key securely\n",
    "openai_api_key = getpass('Enter your API key: ')\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9RKJHGBXvfd"
   },
   "source": [
    "## LLMGuardRuntime\n",
    "\n",
    "Key Features:\n",
    "\n",
    "+ Evaluates function risk using a language model.\n",
    "+ Assigns risk scores based on predefined criteria.\n",
    "+ Provides a mechanism to ignore certain risks if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKcOX661Xvfd",
    "outputId": "aacee56c-7f1e-4220-d98d-f08baeaabb0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 23:26:56,198 - camel - INFO - Camel library logging has been configured.\n",
      "2024-12-12 23:26:57,668 - camel.agents.chat_agent - WARNING - Overriding the configured tools in `BaseModelBackend` with the tools from `ChatAgent`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lxk/camel/camel/toolkits/function_tool.py:384: UserWarning: Function description is missing for \n",
      "                          example_function. This may \n",
      "                          affect the quality of tool calling.\n",
      "  warnings.warn(f\"\"\"Function description is missing for\n",
      "/home/lxk/camel/camel/toolkits/function_tool.py:405: UserWarning: Parameter description is missing for \n",
      "                            {}. This may affect the quality of tool \n",
      "                            calling.\n",
      "  warnings.warn(f\"\"\"Parameter description is missing for\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 23:26:59,417 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 23:26:59,421 - camel.agents.chat_agent - INFO - Model gpt-4o-mini, index 0, processed these messages: [{'role': 'system', 'content': \"You are a function safety evaluator tasked with assessing the \\npotential risk level of a given function based on both its description \\nand parameters. Your goal is to determine if the function may pose any \\nharm to the user's environment, such as deleting files, executing \\narbitrary code, or accessing sensitive information. Pay special attention \\nto the provided parameters â€” even if a function has the potential to be \\ndangerous, its actual parameters may indicate harmless behavior, and the \\nrisk level should be adjusted accordingly. Use the `function_risk` tool to \\nassign a risk score to the function, based on the following criteria:\\n\\n- **Score 1**: No harm. This includes simple operations like mathematical \\n    calculations, content searches, or data retrievals that do not impact \\n    the user's environment or access sensitive resources. This also \\n    includes functions with potentially dangerous capabilities that have \\n    harmless, controlled parameters that ensure safe execution.\\n- **Score 2**: Minimal harm. The function might read user files, retrieve \\n    non-sensitive data, or access other low-risk resources, \\n    posing little risk to the user.\\n- **Score 3**: Risk present. The function might delete files, modify the \\n    file system, execute arbitrary code, or access sensitive data, which \\n    could negatively impact the user's environment. However, if the \\n    actual parameters provided clearly indicate safe and restricted \\n    usage, this risk should be downgraded accordingly.\\n\\nWhen evaluating, always consider both the function's description and its \\nspecific parameters. If the function appears risky due to its design but \\nthe provided parameters indicate a safe and non-impactful operation, \\nadjust the risk score to reflect this. Assign an appropriate risk score \\nand provide a brief explanation of your reasoning based on the function's \\ndescription and the actual parameters given.\\nYOU MUST USE THE `function_risk` TOOL TO ASSESS THE RISK \\nLEVEL OF EACH FUNCTION.\\n\"}, {'role': 'user', 'content': '\\n                    Function is: example_function\\n                    Function description: \\n                    Args: (1, 2)\\n                    Kwargs: {}\\n                    '}]\n",
      "2024-12-12 23:26:59,423 - camel.runtimes.llm_guard_runtime - INFO - Function example_function passed risk assessment.Score: 1, Reason: The function 'example_function' takes two integer arguments and does not have any keyword arguments. Given the simplicity of the parameters and the lack of any harmful operations described, it is assessed to pose no harm.\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from camel.runtimes.llm_guard_runtime import LLMGuardRuntime\n",
    "from camel.toolkits import FunctionTool\n",
    "\n",
    "\n",
    "def example_function(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "tool = FunctionTool(example_function)\n",
    "runtime = LLMGuardRuntime()\n",
    "runtime.add(tool)\n",
    "result = tool.func(1, 2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5scuZsGYGS9"
   },
   "source": [
    "## RemoteHttpRuntime\n",
    "\n",
    "Key Features:\n",
    "\n",
    "+ Executes functions on a remote HTTP server.\n",
    "+ Supports custom entry points and arguments.\n",
    "+ Provides mechanisms to check server status and wait for readiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for runtime to be ready...\n",
      "2024-12-12 23:30:51,108 - camel - INFO - Camel library logging has been configured.\n",
      "2024-12-12 23:30:51,728 - __main__ - INFO - Modules and functions: ['camel.toolkits.MathToolkit']\n",
      "2024-12-12 23:30:51,729 - __main__ - INFO - Importing camel.toolkits and function MathToolkit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Will watch for changes in these directories: ['/home/lxk/camel/docs/cookbooks']\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
      "INFO:     Started reloader process [674247] using WatchFiles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 23:30:52,167 - camel - INFO - Camel library logging has been configured.\n",
      "2024-12-12 23:30:52,819 - __mp_main__ - INFO - Modules and functions: ['camel.toolkits.MathToolkit']\n",
      "2024-12-12 23:30:52,820 - __mp_main__ - INFO - Importing camel.toolkits and function MathToolkit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [674287]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:60696 - \"GET / HTTP/1.1\" 404 Not Found\n",
      "Runtime is ready.\n",
      "INFO:     127.0.0.1:60410 - \"POST /add HTTP/1.1\" 200 OK\n",
      "Add 1 + 2: 3\n",
      "INFO:     127.0.0.1:60420 - \"POST /sub HTTP/1.1\" 200 OK\n",
      "Subtract 5 - 3: 2\n",
      "INFO:     127.0.0.1:60436 - \"POST /multiply HTTP/1.1\" 200 OK\n",
      "Multiply 2 * 3: 6\n",
      "Documents:  http://localhost:8000/docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [674287]\n",
      "INFO:     Stopping reloader process [674247]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<camel.runtimes.remote_http_runtime.RemoteHttpRuntime at 0x7f9fd48f7170>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from camel.runtimes.remote_http_runtime import RemoteHttpRuntime\n",
    "from camel.toolkits.math_toolkit import MathToolkit\n",
    "\n",
    "runtime = (\n",
    "        RemoteHttpRuntime(\"localhost\")\n",
    "        .add(MathToolkit().get_tools(), \"camel.toolkits.MathToolkit\")\n",
    "        .build()\n",
    "    )\n",
    "print(\"Waiting for runtime to be ready...\")\n",
    "runtime.wait()\n",
    "print(\"Runtime is ready.\")\n",
    "add, sub, mul, _, _ = runtime.get_tools()\n",
    "print(f\"Add 1 + 2: {add.func(1, 2)}\")\n",
    "print(f\"Subtract 5 - 3: {sub.func(5, 3)}\")\n",
    "print(f\"Multiply 2 * 3: {mul.func(2, 3)}\")\n",
    "\n",
    "print(\"Documents: \", runtime.docs)\n",
    "# you can open this url in browser to see the API Endpoints\n",
    "# before the runtime is stopped.\n",
    "# time.sleep(60)\n",
    "runtime.stop()\n",
    "# call runtime.stop() if you want to stop the runtime manually\n",
    "# atherwise it will be stopped automatically when the program ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRojeqp7dP1m"
   },
   "source": [
    "## DockerRuntime\n",
    "\n",
    "Key Features:\n",
    "\n",
    "+ Executes functions in Docker containers.\n",
    "+ Supports mounting directories and copying files to containers.\n",
    "+ Provides mechanisms to add tasks and execute commands inside containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 23:34:31,918 - camel.runtimes.docker_runtime - INFO - Copying /home/lxk/camel/camel/runtimes/api.py to /home\n",
      "2024-12-12 23:34:31,983 - camel.runtimes.docker_runtime - INFO - Container started on port 8000\n",
      "Waiting for runtime to be ready...\n",
      "Runtime is ready.\n",
      "Executed the code below:\n",
      "```py\n",
      "2 ** 10\n",
      "```\n",
      "> Executed Results:\n",
      "1024\n",
      "\n",
      "2024-12-12 23:34:46,676 - camel.runtimes.docker_runtime - INFO - Removing container.\n"
     ]
    }
   ],
   "source": [
    "from camel.runtimes import DockerRuntime\n",
    "from camel.toolkits.code_execution import CodeExecutionToolkit\n",
    "\n",
    "\n",
    "# tools\n",
    "toolkit = CodeExecutionToolkit(verbose=True)\n",
    "\n",
    "# change to your own docker image\n",
    "runtime = DockerRuntime(\"xukunliu/camel\").add(\n",
    "    toolkit.get_tools(),\n",
    "    \"camel.toolkits.CodeExecutionToolkit\",\n",
    "    redirect_stdout=True,\n",
    "    arguments=dict(verbose=True),\n",
    ")\n",
    "\n",
    "tool = runtime.get_tools()[0]\n",
    "\n",
    "with runtime as r:\n",
    "    print(\"Waiting for runtime to be ready...\")\n",
    "    r.wait()\n",
    "    print(\"Runtime is ready.\")\n",
    "    tool.func(\"2 ** 10\")\n",
    "\n",
    "print(\"DockerRuntime stopped\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `Runtimes` with Agent\n",
    "\n",
    "In this section, we will demonstrate how to use the `Runtime` with an agent in the CAMEL system. \n",
    "\n",
    "The `Runtime` class provides an `add` function that allows you to add `FunctionTool` instances to the runtime and use `get_tools` to retrieve the wrapped functions. These functions behave exactly like the original functions, and you can add them to the agent just like any other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 23:54:28,291 - camel.agents.chat_agent - WARNING - Overriding the configured tools in `BaseModelBackend` with the tools from `ChatAgent`.\n",
      "2024-12-12 23:54:30,513 - camel.runtimes.docker_runtime - INFO - Copying /home/lxk/camel/camel/runtimes/api.py to /home\n",
      "2024-12-12 23:54:30,605 - camel.runtimes.docker_runtime - INFO - Container started on port 8000\n",
      "\u001b[33muser prompt:\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 51 minutes of babysitting. How much did she earn?\n",
      "\n",
      "2024-12-12 23:54:38,240 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 23:54:38,304 - camel.agents.chat_agent - INFO - Model gpt-4o, index 0, processed these messages: [{'role': 'system', 'content': 'You are a personal math tutor and programmer. When asked a math question, write and run Python code to answer the question.'}, {'role': 'user', 'content': 'Weng earns $12 an hour for babysitting. Yesterday, she just did 51 minutes of babysitting. How much did she earn?'}]\n",
      "\n",
      "2024-12-12 23:54:38,944 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 23:54:38,947 - camel.agents.chat_agent - INFO - Model gpt-4o, index 0, processed these messages: [{'role': 'system', 'content': 'You are a personal math tutor and programmer. When asked a math question, write and run Python code to answer the question.'}, {'role': 'user', 'content': 'Weng earns $12 an hour for babysitting. Yesterday, she just did 51 minutes of babysitting. How much did she earn?'}, {'role': 'assistant', 'content': '', 'function_call': {'name': 'execute_code', 'arguments': '{\\'code\\': \"# Weng\\'s hourly rate\\\\nhourly_rate = 12\\\\n\\\\n# Time spent babysitting in minutes\\\\ntime_in_minutes = 51\\\\n\\\\n# Convert minutes to hours\\\\nhours_worked = time_in_minutes / 60\\\\n\\\\n# Calculate earnings\\\\nearnings = hourly_rate * hours_worked\\\\nearnings\"}'}}, {'role': 'function', 'name': 'execute_code', 'content': '{\\'result\\': {\"Executed the code below:\\\\n```py\\\\n# Weng\\'s hourly rate\\\\nhourly_rate = 12\\\\n\\\\n# Time spent babysitting in minutes\\\\ntime_in_minutes = 51\\\\n\\\\n# Convert minutes to hours\\\\nhours_worked = time_in_minutes / 60\\\\n\\\\n# Calculate earnings\\\\nearnings = hourly_rate * hours_worked\\\\nearnings\\\\n```\\\\n> Executed Results:\\\\n10.2\"}}'}]\n",
      "2024-12-12 23:54:38,950 - camel.camel.utils.commons - INFO - \n",
      "\u001b[32mAgent response:\n",
      "Weng earned $10.20 for 51 minutes of babysitting.\n",
      "2024-12-12 23:54:40,441 - camel.camel.utils.commons - INFO - \n",
      "2024-12-12 23:54:51,053 - camel.runtimes.docker_runtime - INFO - Removing container.\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore\n",
    "from camel.agents import ChatAgent\n",
    "from camel.configs import ChatGPTConfig\n",
    "from camel.messages import BaseMessage\n",
    "from camel.models import ModelFactory\n",
    "from camel.runtimes import DockerRuntime\n",
    "from camel.toolkits.code_execution import CodeExecutionToolkit\n",
    "from camel.types import ModelPlatformType, ModelType\n",
    "from camel.utils import print_text_animated\n",
    "\n",
    "# Initialize the CodeExecutionToolkit\n",
    "toolkit = CodeExecutionToolkit(verbose=True)\n",
    "\n",
    "# Initialize the DockerRuntime with a specified Docker image\n",
    "runtime = DockerRuntime(\"xukunliu/camel\").add(\n",
    "    toolkit.get_tools(),\n",
    "    \"camel.toolkits.CodeExecutionToolkit\",\n",
    "    redirect_stdout=True,\n",
    ")\n",
    "\n",
    "# Retrieve the tools from the runtime\n",
    "tools = runtime.get_tools()\n",
    "\n",
    "# Configure the language model\n",
    "assistant_model_config = ChatGPTConfig(\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Create the model using the ModelFactory\n",
    "model = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.DEFAULT,\n",
    "    model_type=ModelType.GPT_4O,\n",
    "    model_config_dict=assistant_model_config.as_dict(),\n",
    ")\n",
    "\n",
    "# Create the system message for the agent\n",
    "assistant_sys_msg = BaseMessage.make_assistant_message(\n",
    "    role_name=\"Teacher\",\n",
    "    content=(\n",
    "        \"You are a personal math tutor and programmer. \"\n",
    "        \"When asked a math question, \"\n",
    "        \"write and run Python code to answer the question.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Initialize the ChatAgent with the system message, model, and tools\n",
    "agent = ChatAgent(\n",
    "    assistant_sys_msg,\n",
    "    model,\n",
    "    tools=tools,\n",
    ")\n",
    "agent.reset()\n",
    "\n",
    "# Use the runtime to execute the task\n",
    "with runtime as r:\n",
    "    r.wait()\n",
    "    prompt = (\n",
    "        \"Weng earns $12 an hour for babysitting. \"\n",
    "        \"Yesterday, she just did 51 minutes of babysitting. How much did she earn?\"\n",
    "    )\n",
    "    user_msg = BaseMessage.make_user_message(role_name=\"User\", content=prompt)\n",
    "    print(Fore.YELLOW + f\"user prompt:\\n{prompt}\\n\")\n",
    "\n",
    "    # Get the agent's response to the user message\n",
    "    response = agent.step(user_msg)\n",
    "    for msg in response.msgs:\n",
    "        print_text_animated(Fore.GREEN + f\"Agent response:\\n{msg.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYNA7G06FJRq"
   },
   "source": [
    "In this session, we introduced the BaseRuntime class and its specific runtime implementations. These components play essential roles in the CAMEL system, facilitating the execution of functions in various environments with safety, remote execution, and containerized execution."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
