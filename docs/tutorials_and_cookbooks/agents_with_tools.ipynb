{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssX_map8c6mx"
      },
      "source": [
        "# 🐫 CAMEL Tools Cookbook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1K3dKYUdMqJ"
      },
      "source": [
        "In this notebook, we show the useage of CAMEL Tools with `ChatAgent`.\n",
        "\n",
        "2 main parts included:\n",
        "- Using Tools Integrated by CAMEL\n",
        "- Customize Your Own Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1W4sgCoEdEpg",
        "outputId": "02a3d71c-6813-40cd-937a-0af4d81efb89"
      },
      "outputs": [],
      "source": [
        "!pip install camel-ai[all]==0.1.6.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2g6PymaWPdE"
      },
      "source": [
        "Import CAMEL modules, for the tool part we will take search tool as one example, other tools are commented out.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Di3R-xNNviB"
      },
      "outputs": [],
      "source": [
        "from camel.agents import ChatAgent\n",
        "from camel.configs import ChatGPTConfig\n",
        "from camel.toolkits import (\n",
        "    SEARCH_FUNCS,\n",
        "    # MAP_FUNCS,\n",
        "    # MATH_FUNCS,\n",
        "    # TWITTER_FUNCS,\n",
        "    # WEATHER_FUNCS,\n",
        "    # RETRIEVAL_FUNCS,\n",
        "    # TWITTER_FUNCS,\n",
        "    # SLACK_FUNCS,\n",
        ")\n",
        "from camel.messages import BaseMessage\n",
        "from camel.models import ModelFactory\n",
        "from camel.types import ModelPlatformType, ModelType\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OmxjHKPWgp0"
      },
      "source": [
        "Set your OpenAI key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICse1xFtSFvf",
        "outputId": "8eefd4e6-530a-49cb-c34b-0ee0a76d4e90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your API key: ··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Prompt for the API key securely\n",
        "openai_api_key = getpass('Enter your API key: ')\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ1J9e4mWkBZ"
      },
      "source": [
        "Let's customize one tool, take the simple math calactor as one example, when you define your own function, please make sure the argument name and docstring is clear, Agent will try to understand what this function can do and when to use the function based on the function information you provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPOqaGYaXDlH"
      },
      "outputs": [],
      "source": [
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    r\"\"\"Adds two numbers.\n",
        "\n",
        "    Args:\n",
        "        a (int): The first number to be added.\n",
        "        b (int): The second number to be added.\n",
        "\n",
        "    Returns:\n",
        "        integer: The sum of the two numbers.\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def sub(a: int, b: int) -> int:\n",
        "    r\"\"\"Do subtraction between two numbers.\n",
        "\n",
        "    Args:\n",
        "        a (int): The minuend in subtraction.\n",
        "        b (int): The subtrahend in subtraction.\n",
        "\n",
        "    Returns:\n",
        "        integer: The result of subtracting :obj:`b` from :obj:`a`.\n",
        "    \"\"\"\n",
        "    return a - b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv0pYDQvXGER"
      },
      "source": [
        "Add these 2 customized functions as CAMEL's OpenAIFunction list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWGxfYn6VbTw"
      },
      "outputs": [],
      "source": [
        "from camel.toolkits import OpenAIFunction\n",
        "\n",
        "\n",
        "MATH_FUNCS: list[OpenAIFunction] = [\n",
        "    OpenAIFunction(func) for func in [add, sub]\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfhwO6_HXVj3"
      },
      "source": [
        "Add the tool from CAMEL and defined by yourself to the tool list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2LQwcVeXfTC"
      },
      "outputs": [],
      "source": [
        "tool_list = [*SEARCH_FUNCS, *MATH_FUNCS]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B00S0YeWXhjk"
      },
      "source": [
        "Set the ChatAgent able to call the tool\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJRlrUFnOj4v"
      },
      "outputs": [],
      "source": [
        "# Set the backend mode, this model should support tool calling\n",
        "model=ModelFactory.create(\n",
        "    model_platform=ModelPlatformType.OPENAI,\n",
        "    model_type=ModelType.GPT_3_5_TURBO,\n",
        "    model_config_dict=ChatGPTConfig(\n",
        "        tools=tool_list,\n",
        "        temperature=0.0,\n",
        "    ).__dict__,\n",
        ")\n",
        "\n",
        "# Set message for the assistant\n",
        "assistant_sys_msg = BaseMessage.make_assistant_message(\n",
        "    role_name=\"Search Agent\",\n",
        "    content= \"\"\"You are a helpful assistant to do search task.\"\"\"\n",
        ")\n",
        "\n",
        "# Set the config parameter for the model\n",
        "assistant_model_config = ChatGPTConfig(\n",
        "    tools=tool_list,\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "# Set the agent\n",
        "agent = ChatAgent(\n",
        "    assistant_sys_msg,\n",
        "    model=model,\n",
        "    tools=tool_list\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiXsPSsUYkmY"
      },
      "source": [
        "Let's define two test prompt for the agent to run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFI2B-prYqfX"
      },
      "outputs": [],
      "source": [
        "# Set prompt for the search task\n",
        "prompt_search = (\"\"\"When was University of Oxford set up\"\"\")\n",
        "# Set prompt for the calculation task\n",
        "prompt_calculate = (\"\"\"Assume now is 2024 in the Gregorian calendar, University of Oxford was set up in 1096, estimate the current age of University of Oxford\"\"\")\n",
        "\n",
        "# Convert the two prompt as message that can be accepted by the Agent\n",
        "user_msg_search = BaseMessage.make_user_message(role_name=\"User\", content=prompt_search)\n",
        "user_msg_calculate = BaseMessage.make_user_message(role_name=\"User\", content=prompt_calculate)\n",
        "\n",
        "# Get response\n",
        "assistant_response_search = agent.step(user_msg_search)\n",
        "assistant_response_calculate = agent.step(user_msg_calculate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF3Sg9h7ZHcq"
      },
      "source": [
        "Let's see how did the agent use the tool for the 2 tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZxoXxQ-TJRn",
        "outputId": "7074a385-366c-4aeb-807c-a0c548bd66fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FunctionCallingRecord(func_name='search_wiki', args={'entity': 'University of Oxford'}, result=\"The University of Oxford is a collegiate research university in Oxford, England. There is evidence of teaching as early as 1096, making it the oldest university in the English-speaking world and the world's second-oldest university in continuous operation. It grew rapidly from 1167, when Henry II banned English students from attending the University of Paris. After disputes between students and Oxford townsfolk, some Oxford academics fled northeast to Cambridge, where, in 1209, they established the University of Cambridge. The two English ancient universities share many common features and are jointly referred to as Oxbridge.\")]\n"
          ]
        }
      ],
      "source": [
        "print(assistant_response_search.info['tool_calls'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arIWzrtyWVqX",
        "outputId": "6d48abb4-8705-43fa-cb19-db45dfbc4b41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FunctionCallingRecord(func_name='sub', args={'a': 2024, 'b': 1096}, result=928)]\n"
          ]
        }
      ],
      "source": [
        "print(assistant_response_calculate.info['tool_calls'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWib8WZOZQeA"
      },
      "source": [
        "Now the single agent has the ability to use tool, let set one small AI society, the society would include one user agent and one assistant agent, the assistant agent is the one we just set can use tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeRHdVnmXd6d"
      },
      "outputs": [],
      "source": [
        "from camel.societies import RolePlaying\n",
        "from camel.agents.chat_agent import FunctionCallingRecord\n",
        "from camel.utils import print_text_animated\n",
        "from colorama import Fore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJX-E1V-XQv7",
        "outputId": "d5206bf5-8fdc-470a-81d4-7b7b25debd94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mAI Assistant sys message:\n",
            "BaseMessage(role_name='Searcher', role_type=<RoleType.ASSISTANT: 'assistant'>, meta_dict={'task': 'Assume now is 2024 in the Gregorian calendar, estimate the current age of University of Oxford and then add 10 more years to this age.', 'assistant_role': 'Searcher', 'user_role': 'Professor'}, content='===== RULES OF ASSISTANT =====\\nNever forget you are a Searcher and I am a Professor. Never flip roles! Never instruct me!\\nWe share a common interest in collaborating to successfully complete a task.\\nYou must help me to complete the task.\\nHere is the task: Assume now is 2024 in the Gregorian calendar, estimate the current age of University of Oxford and then add 10 more years to this age.. Never forget our task!\\nI must instruct you based on your expertise and my needs to complete the task.\\n\\nI must give you one instruction at a time.\\nYou must write a specific solution that appropriately solves the requested instruction and explain your solutions.\\nYou must decline my instruction honestly if you cannot perform the instruction due to physical, moral, legal reasons or your capability and explain the reasons.\\nUnless I say the task is completed, you should always start with:\\n\\nSolution: <YOUR_SOLUTION>\\n\\n<YOUR_SOLUTION> should be very specific, include detailed explanations and provide preferable detailed implementations and examples and lists for task-solving.\\nAlways end <YOUR_SOLUTION> with: Next request.', video_bytes=None, image_list=None, image_detail='auto', video_detail='low')\n",
            "\n",
            "\u001b[34mAI User sys message:\n",
            "BaseMessage(role_name='Professor', role_type=<RoleType.USER: 'user'>, meta_dict={'task': 'Assume now is 2024 in the Gregorian calendar, estimate the current age of University of Oxford and then add 10 more years to this age.', 'assistant_role': 'Searcher', 'user_role': 'Professor'}, content='===== RULES OF USER =====\\nNever forget you are a Professor and I am a Searcher. Never flip roles! You will always instruct me.\\nWe share a common interest in collaborating to successfully complete a task.\\nI must help you to complete the task.\\nHere is the task: Assume now is 2024 in the Gregorian calendar, estimate the current age of University of Oxford and then add 10 more years to this age.. Never forget our task!\\nYou must instruct me based on my expertise and your needs to solve the task ONLY in the following two ways:\\n\\n1. Instruct with a necessary input:\\nInstruction: <YOUR_INSTRUCTION>\\nInput: <YOUR_INPUT>\\n\\n2. Instruct without any input:\\nInstruction: <YOUR_INSTRUCTION>\\nInput: None\\n\\nThe \"Instruction\" describes a task or question. The paired \"Input\" provides further context or information for the requested \"Instruction\".\\n\\nYou must give me one instruction at a time.\\nI must write a response that appropriately solves the requested instruction.\\nI must decline your instruction honestly if I cannot perform the instruction due to physical, moral, legal reasons or my capability and explain the reasons.\\nYou should instruct me not ask me questions.\\nNow you must start to instruct me using the two ways described above.\\nDo not add anything else other than your instruction and the optional corresponding input!\\nKeep giving me instructions and necessary inputs until you think the task is completed.\\nWhen the task is completed, you must only reply with a single word <CAMEL_TASK_DONE>.\\nNever say <CAMEL_TASK_DONE> unless my responses have solved your task.', video_bytes=None, image_list=None, image_detail='auto', video_detail='low')\n",
            "\n",
            "\u001b[33mOriginal task prompt:\n",
            "Assume now is 2024 in the Gregorian calendar, estimate the current age of University of Oxford and then add 10 more years to this age.\n",
            "\n",
            "\u001b[36mSpecified task prompt:\n",
            "None\n",
            "\n",
            "\u001b[31mFinal task prompt:\n",
            "Assume now is 2024 in the Gregorian calendar, estimate the current age of University of Oxford and then add 10 more years to this age.\n",
            "\n",
            "\u001b[34mAI User:\n",
            "\n",
            "Instruction: Provide the founding year of the University of Oxford.\n",
            "Input: None\n",
            "\n",
            "\n",
            "\u001b[32mAI Assistant:\n",
            "\n",
            "Function Execution: search_wiki\n",
            "\tArgs: {'entity': 'University of Oxford'}\n",
            "\tResult: The University of Oxford is a collegiate research university in Oxford, England. There is evidence of teaching as early as 1096, making it the oldest university in the English-speaking world and the world's second-oldest university in continuous operation. It grew rapidly from 1167, when Henry II banned English students from attending the University of Paris. After disputes between students and Oxford townsfolk, some Oxford academics fled northeast to Cambridge, where, in 1209, they established the University of Cambridge. The two English ancient universities share many common features and are jointly referred to as Oxbridge.\n",
            "\n",
            "The University of Oxford was founded in 1096, making it the oldest university in the English-speaking world. \n",
            "\n",
            "Next request.\n",
            "\n",
            "\n",
            "\u001b[34mAI User:\n",
            "\n",
            "Instruction: Calculate the current age of the University of Oxford in 2024.\n",
            "Input: 2024, founding year of the University of Oxford (1096)\n",
            "\n",
            "\n",
            "\u001b[32mAI Assistant:\n",
            "\n",
            "Function Execution: sub\n",
            "\tArgs: {'a': 2024, 'b': 1096}\n",
            "\tResult: 928\n",
            "\n",
            "The current age of the University of Oxford in 2024 is 928 years.\n",
            "\n",
            "Next request.\n",
            "\n",
            "\n",
            "\u001b[34mAI User:\n",
            "\n",
            "Instruction: Add 10 years to the current age of the University of Oxford.\n",
            "Input: 928 years (current age of the University of Oxford in 2024)\n",
            "\n",
            "\n",
            "\u001b[32mAI Assistant:\n",
            "\n",
            "Function Execution: add\n",
            "\tArgs: {'a': 928, 'b': 10}\n",
            "\tResult: 938\n",
            "\n",
            "Adding 10 years to the current age of the University of Oxford in 2024 results in a total of 938 years.\n",
            "\n",
            "Next request.\n",
            "\n",
            "\n",
            "\u001b[34mAI User:\n",
            "\n",
            "Instruction: <CAMEL_TASK_DONE>\n",
            "\n",
            "\n",
            "\u001b[32mAI Assistant:\n",
            "\n",
            "Task completed.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Set a task\n",
        "task_prompt=(\"Assume now is 2024 in the Gregorian calendar, \"\n",
        "        \"estimate the current age of University of Oxford \"\n",
        "        \"and then add 10 more years to this age.\")\n",
        "\n",
        "# Set role playing\n",
        "role_play_session = RolePlaying(\n",
        "    assistant_role_name=\"Searcher\",\n",
        "    user_role_name=\"Professor\",\n",
        "    assistant_agent_kwargs=dict(\n",
        "        model=ModelFactory.create(\n",
        "            model_platform=ModelPlatformType.OPENAI,\n",
        "            model_type=ModelType.GPT_3_5_TURBO,\n",
        "            model_config_dict=assistant_model_config.__dict__,\n",
        "        ),\n",
        "        tools=tool_list,\n",
        "    ),\n",
        "    user_agent_kwargs=dict(\n",
        "        model=ModelFactory.create(\n",
        "            model_platform=ModelPlatformType.OPENAI,\n",
        "            model_type=ModelType.GPT_3_5_TURBO,\n",
        "            model_config_dict=ChatGPTConfig(temperature=0.0).__dict__,\n",
        "        ),\n",
        "    ),\n",
        "    task_prompt=task_prompt,\n",
        "    with_task_specify=False,\n",
        ")\n",
        "\n",
        "# Set the limit for the chat turn\n",
        "chat_turn_limit=10\n",
        "\n",
        "print(\n",
        "    Fore.GREEN\n",
        "    + f\"AI Assistant sys message:\\n{role_play_session.assistant_sys_msg}\\n\"\n",
        ")\n",
        "print(\n",
        "    Fore.BLUE + f\"AI User sys message:\\n{role_play_session.user_sys_msg}\\n\"\n",
        ")\n",
        "\n",
        "print(Fore.YELLOW + f\"Original task prompt:\\n{task_prompt}\\n\")\n",
        "print(\n",
        "    Fore.CYAN\n",
        "    + \"Specified task prompt:\"\n",
        "    + f\"\\n{role_play_session.specified_task_prompt}\\n\"\n",
        ")\n",
        "print(Fore.RED + f\"Final task prompt:\\n{role_play_session.task_prompt}\\n\")\n",
        "\n",
        "n = 0\n",
        "input_msg = role_play_session.init_chat()\n",
        "while n < chat_turn_limit:\n",
        "    n += 1\n",
        "    assistant_response, user_response = role_play_session.step(input_msg)\n",
        "\n",
        "    if assistant_response.terminated:\n",
        "        print(\n",
        "            Fore.GREEN\n",
        "            + (\n",
        "                \"AI Assistant terminated. Reason: \"\n",
        "                f\"{assistant_response.info['termination_reasons']}.\"\n",
        "            )\n",
        "        )\n",
        "        break\n",
        "    if user_response.terminated:\n",
        "        print(\n",
        "            Fore.GREEN\n",
        "            + (\n",
        "                \"AI User terminated. \"\n",
        "                f\"Reason: {user_response.info['termination_reasons']}.\"\n",
        "            )\n",
        "        )\n",
        "        break\n",
        "\n",
        "    # Print output from the user\n",
        "    print_text_animated(\n",
        "        Fore.BLUE + f\"AI User:\\n\\n{user_response.msg.content}\\n\"\n",
        "    )\n",
        "\n",
        "    # Print output from the assistant, including any function\n",
        "    # execution information\n",
        "    print_text_animated(Fore.GREEN + \"AI Assistant:\")\n",
        "    tool_calls: list[FunctionCallingRecord] = assistant_response.info[\n",
        "        'tool_calls'\n",
        "    ]\n",
        "    for func_record in tool_calls:\n",
        "        print_text_animated(f\"{func_record}\")\n",
        "    print_text_animated(f\"{assistant_response.msg.content}\\n\")\n",
        "\n",
        "    if \"CAMEL_TASK_DONE\" in user_response.msg.content:\n",
        "        break\n",
        "\n",
        "    input_msg = assistant_response.msg"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
